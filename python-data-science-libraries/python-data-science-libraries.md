# Python Libraries for Data Science (Beginner Friendly Guide)

Python is one of the most popular languages for data science because it has a **rich ecosystem of libraries**.  
You do *not* need to learn all of them at once.

This guide introduces the **most important and commonly used Python libraries for data science**, explained in a simple
way for beginners.

---

## Core Numerical & Data Handling Libraries

These libraries form the foundation of data science in Python.

### 1. NumPy

Used for numerical computing.

- Works with arrays and matrices
- Performs fast mathematical operations
- Foundation for many other libraries

**Use NumPy when:**  
You need to work with numbers, vectors, or matrices efficiently.

---

### 2. Pandas

Used for data analysis and data manipulation.

- Works with tables of data (DataFrames)
- Reads CSV, Excel, and SQL data
- Cleans, filters, and transforms data

**Use Pandas when:**  
You are working with real-world datasets.

---

### 3. SciPy

Used for scientific and advanced mathematical computing.

- Statistics
- Optimization
- Numerical calculations

**Use SciPy when:**  
NumPy alone is not enough for advanced math or statistics.

---

## Data Visualization Libraries

Used to understand data through charts and graphs.

### 4. Matplotlib

Basic plotting library.

- Line charts
- Bar charts
- Scatter plots
- Histograms

**Use Matplotlib when:**  
You need full control over how a plot looks.

---

### 5. Seaborn

Built on top of Matplotlib.

- Cleaner and more attractive charts
- Statistical visualizations
- Less code than Matplotlib

**Use Seaborn when:**  
You want quick, beautiful charts.

---

### 6. Plotly

Used for interactive visualizations.

- Hover effects
- Zooming
- Dashboards

**Use Plotly when:**  
You want interactive charts for web apps or presentations.

---

### 7. Bokeh

Another interactive visualization library.

- Browser-based plots

**Use Bokeh when:**  
You need interactive visuals without heavy setup.

---

## Statistics & Mathematical Analysis

### 8. Statsmodels

Used for statistical modeling.

- Regression analysis
- Hypothesis testing
- Time-series analysis

**Use Statsmodels when:**  
You are doing formal statistical analysis.

---

### 9. Pingouin

Simple and beginner-friendly statistics library.

- t-tests
- ANOVA
- Correlation tests

**Use Pingouin when:**  
You want easy-to-read statistical results.

---

## Machine Learning Libraries

Used to build models that learn from data.

### 10. Scikit-learn

The most important machine learning library.

- Classification
- Regression
- Clustering
- Data preprocessing

**Use Scikit-learn when:**  
You are learning or applying traditional machine learning.

---

### 11. XGBoost

High-performance machine learning library.

- Gradient boosting models

**Use XGBoost when:**  
You want very accurate models for structured data.

---

### 12. LightGBM

Fast and efficient boosting library.

- Handles large datasets well

**Use LightGBM when:**  
Speed and performance matter.

---

### 13. CatBoost

Machine learning with categorical data.

- Handles text-like categories automatically

**Use CatBoost when:**  
Your dataset has many categorical columns.

---

## Deep Learning Libraries

Used for neural networks and advanced AI.

### 14. TensorFlow

Deep learning framework.

- Neural networks
- Production-ready models

---

### 15. Keras

High-level API built on TensorFlow.

- Easy to learn
- Beginner-friendly

---

### 16. PyTorch

Popular deep learning library.

- Flexible
- Widely used in research

---

### 17. FastAI

Built on top of PyTorch.

- Less code
- Faster experimentation

---

## Working with Files & Data Formats

### 18. OpenPyXL

Used to read and write Excel files.

---

### 19. xlrd / xlsxwriter

Used for Excel file handling.

---

### 20. PyArrow

Used for Parquet and Arrow file formats.

- Common in big data projects

---

### 21. h5py

Used for storing large numerical datasets.

---

## Databases & Big Data

### 22. SQLAlchemy

Used to connect Python to databases.

- PostgreSQL
- MySQL
- SQLite

**Very important for real-world projects.**

---

### 23. psycopg2

Used to connect to PostgreSQL databases.

---

### 24. PyMySQL

Used to connect to MySQL databases.

---

### 25. Dask

Used for large datasets.

- Works like Pandas
- Faster for big data

---

### 26. PySpark

Used with Apache Spark.

- Distributed data processing

---

## Notebooks & Experimentation

### 27. Jupyter Notebook

Interactive coding environment.

- Code
- Notes
- Visuals in one place

---

### 28. JupyterLab

Advanced version of Jupyter Notebook.

---

### 29. IPython

Enhanced Python shell.

---

## Natural Language Processing (NLP)

### 30. NLTK

Basic natural language processing.

- Tokenization
- Text processing

---

### 31. spaCy

Industrial-strength NLP library.

---

### 32. Transformers (Hugging Face)

Modern NLP models.

- Text classification
- Language models

---

## Time Series & Forecasting

### 33. Prophet

Time series forecasting.

- Business-friendly
- Easy to use

---

### 34. statsforecast

Scalable time-series models.

---

## Model Explainability

### 35. SHAP

Explains model predictions.

---

### 36. LIME

Explains individual predictions.

---

## Utilities & Productivity

### 37. Requests

Used to work with APIs and HTTP requests.

---

### 38. BeautifulSoup

Used for web scraping.

---

### 39. Scrapy

Used for large-scale web scraping.

---

### 40. MLflow

Used to track experiments and models.

---

## Recommended Learning Priority (For Beginners)

### Start with these first:

- NumPy
- Pandas
- Matplotlib
- Seaborn
- Scikit-learn
- SQLAlchemy

### Learn later:

- Statsmodels
- Plotly
- XGBoost or LightGBM

---

## TIP

You do **not** need to learn everything here to be effective.  
Master the basics, build projects, and add new libraries as needed.


